{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Webscraper für die Zeitungsliste von DigiPress**"
      ],
      "metadata": {
        "id": "vF6wjJLeSa8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vorbereitung"
      ],
      "metadata": {
        "id": "JDM3MMB_SaA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installation benötigter Python-Bibliotheken\n",
        "\n",
        "import requests # Bibliothek zur Kommunikation über HTTP (Hypertext Transfer Protocol)\n",
        "from bs4 import BeautifulSoup # Bibliothek für Webcrawling/Screenscraping, Parsen von HTML und XML\n",
        "import pandas as pd # Bibliothek zur Datenverarbeitung, -analyse und -darstellung"
      ],
      "metadata": {
        "id": "dhFlmODqSV13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HTML der Zeitungsliste laden"
      ],
      "metadata": {
        "id": "7YEnp1hOS5Je"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GngIWIxFRV83",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# URL der Website\n",
        "url = \"https://digipress.digitale-sammlungen.de/titles\"\n",
        "\n",
        "# HTTP-Anfrage über Requests = Sammeln des HTMLs\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # Fehlermeldung bei Problemen\n",
        "\n",
        "# HTML der Website parsen = BeautifulSoup liest den von Requests erhaltenen Output als HTML ein\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# HTML der Website zur Kontrolle ausgeben\n",
        "print(soup)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HTML parsen und Metadaten extrahieren"
      ],
      "metadata": {
        "id": "I41IPM4xNt8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leere Liste für zu sammelnde Informationen anlegen\n",
        "data = []\n",
        "\n",
        "# Für jedes div-Element der Klasse \"seriesItem\" (Suche über .find_all-Funktion von Beautiful Soup)\n",
        "for series_item in soup.find_all('div', class_='seriesItem'):\n",
        "\n",
        "    # Platzhalter erstellen (= zu befüllende Spalten)\n",
        "    title = None\n",
        "    digipress_id = None\n",
        "    zeitungsunternehmen = None\n",
        "\n",
        "    #Teil 1: Verarbeitung von Überschriften (<h4>)\n",
        "\n",
        "    # Suche nach <h4>-Elementen (sollte in jedem \"seriesItem\" vorhanden sein, Suche über .find-Funktion von Beautiful Soup)\n",
        "    h4 = series_item.find('h4')\n",
        "\n",
        "    # Fall 1: <h4> mit name=\"digiPressID\" - Beispiel: Aarauer Zeitung\n",
        "    if h4 and h4.has_attr('name'): # Falls <h4>-Element mit \"name\"-Attribut gefunden:\n",
        "\n",
        "        # digiPress-ID (digipress_id) identifizieren\n",
        "        digipress_id = h4['name'] # Aus Attribut extrahieren\n",
        "\n",
        "        # Zeitungstitel (title) identifizieren\n",
        "        title_element = h4.find('a', class_='newspaperTitle') # Finde <a>-Element mit Klasse \"newspaperTitle\"\n",
        "        if title_element: #Wenn gefunden:\n",
        "          title = title_element.text.strip() #Text in Element von vor- oder nachgestelltem Whitespace bereinigen (.strip()-Funktion) und als Titel speichern\n",
        "\n",
        "    # Fall 2: <h4> mit class=\"noLink\" - Beispiel:\n",
        "    elif h4 and 'noLink' in h4.get('class', []): # Elif = else if, d.h. ansonsten: Falls <h4>-Element gefunden und Klasse = \"noLink\":\n",
        "\n",
        "        # Zeitungstitel (title) identifizieren\n",
        "        span = h4.find('span', recursive=False)  # Finde das erste <span>-Element ohne Attribute\n",
        "        if span: # Falls gefunden:\n",
        "          title = span.text.strip() # Text bereinigen und als Titel speichern\n",
        "\n",
        "        # Zeitungsunternehmen (zeitungsunternehmen) und digiPress-ID (id)\n",
        "        link_element = series_item.find('a', class_='smaller linkToPrimaryTitle') # Finde <a>-Element mit Klasse \"smaller linktoPrimaryTitle\"\n",
        "        if link_element: # Falls gefunden:\n",
        "\n",
        "            #zeitungsunternehmen\n",
        "            zeitungsunternehmen = link_element.text.strip() # Bereinigten Text in Linkelement als Zeitungsunternehmen speichern\n",
        "\n",
        "            # digiPress-id (digipress_id)\n",
        "            if link_element.has_attr('href'): # Falls Element Attribut \"href\" hat:\n",
        "              digipress_id = link_element['href'].strip(\"#\") # URL aus Attribut extrahieren - \"#\" entfernen\n",
        "\n",
        "    # Teil 2: Verarbeitung von Metadaten (<dl>)\n",
        "\n",
        "    # Leeres Dictionary (= Liste von Paaren aus Schlüssel und Wert) für Metadaten anlegen\n",
        "    metadata = {}\n",
        "\n",
        "    # Finde <dl>-Element mit der Klasse \"seriesItemMeta\"\n",
        "    meta_container = series_item.find('dl', class_='seriesItemMeta')\n",
        "\n",
        "    if meta_container: # Falls gefunden:\n",
        "        for dt, dd in zip(meta_container.find_all('dt'), meta_container.find_all('dd')): # Für alle <dt> und <dd>-Elemente (je durch zip()-Funktion zu Paar verbunden):\n",
        "            metadata[dt.text.strip()] = dd.text.strip() # Daten speichern: dt = Schlüssel (z.B. \"Erscheinungsverlauf\"), dd = Wert (z.B. \"1815-1821\")\n",
        "\n",
        "    # Einen Eintrag pro Zeitungstitel (im Sinne von <div>-Element) anhand der Informationen aus <h4> erstellen\n",
        "    entry = {\n",
        "        \"Titel\": title,\n",
        "        \"digiPress-ID\": digipress_id,\n",
        "        \"Unternehmen\": zeitungsunternehmen,\n",
        "    }\n",
        "    entry.update(metadata) # Metadaten aus <dl> hinzufügen\n",
        "    data.append(entry) # Eintrag zu Gesamtdaten hinzufügen\n",
        "\n",
        "# Gesamtdaten in Pandas DataFrame umwandeln\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# DataFrame anzeigen\n",
        "df"
      ],
      "metadata": {
        "id": "xbpisfi8Y5XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ergänzung der Daten"
      ],
      "metadata": {
        "id": "ZlQiQkM9BM89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frage:** Welche wichtigen Informationen fehlen noch?"
      ],
      "metadata": {
        "id": "lTaalrUgBjdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aufgabe:** Welcher Wert gehört in die Spalte \"Unternehmen\", wenn None statt einem tatsächlichen Namen gegeben ist? Welche Spalte muss in der Code-Zelle unterhalb eingesetzt werden?"
      ],
      "metadata": {
        "id": "opOS07To9Vbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ergänzung von Namen des Zeitungsunternehmen, wo None\n",
        "\n",
        "df.loc[df[\"Unternehmen\"].isna(), \"Unternehmen\"] = df[\"???\"] # Für Zeilen, wo \"Unternehmen\" leer ist, soll Wert der Spalte ??? übernommen werden\n",
        "df"
      ],
      "metadata": {
        "id": "1MWV3f2q9K7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Link ergänzen\n",
        "\n",
        "base_url = \"https://digipress.digitale-sammlungen.de/calendar/newspaper/\" # Basis-URL für die Kalenderansicht: DigiPress-ID muss je am Ende hinzugefügt werden\n",
        "df[\"Link\"] = \"https://digipress.digitale-sammlungen.de/calendar/newspaper/\" + df[\"digiPress-ID\"]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "nEpYGXu__Yo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Genauerer Blick in die Daten"
      ],
      "metadata": {
        "id": "JKPSqingrvYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wie viele Einträge umfasst die Zeitungsliste überhaupt?\n",
        "\n",
        "**Erinnerung:** Zeitungsunternehmen (mit unterschiedlicher digiPress-ID) versus Zeitungstitel (mit unterschiedlicher ZDB-ID)"
      ],
      "metadata": {
        "id": "2NFpTAxpCB2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wie viele unterschiedliche Zeitungstitel (= ZDB-IDs) umfasst die Zeitungsliste?\n",
        "\n",
        "count = df['ZDB-ID'].nunique()\n",
        "print(f\"Anzahl an Zeitungstitel: {count}\")"
      ],
      "metadata": {
        "id": "APeAAv1PtSG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wie viele unterschiedliche Zeitungsunternehmen (= digiPress-ID) sind gelistet?\n",
        "\n",
        "count = df['digiPress-ID'].nunique()\n",
        "print(f\"Anzahl an Zeitungsunternehmen: {count}\")"
      ],
      "metadata": {
        "id": "yXcAvzKRdl8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Welche Spalten sind für die Analyse von Interesse?"
      ],
      "metadata": {
        "id": "0IvhmppkLTAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wie viele Titel haben Informationen einer bestimmten Metadaten-Kategorie oder Spalte (\"z.B. Paralleltitel\")?\n",
        "\n",
        "count = df['Paralleltitel'].notna().sum() #Zähle die Werte, die nicht leer sind\n",
        "print(count)"
      ],
      "metadata": {
        "id": "PpQzFzoLr2C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wie viele unterschiedliche Werte hat eine bestimmte Spalte?\n",
        "\n",
        "print(len(df[\"Paralleltitel\"].unique())) # Gib die Anzahl einzigartiger Werte einer Spalte aus (len() ermittelt Länge einer Liste)"
      ],
      "metadata": {
        "id": "Mawgc04tuxnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wie sehen die Werte einer bestimmten Spalte aus?\n",
        "\n",
        "print(df[\"Paralleltitel\"].unique()) # Gib die einzigartigen Werte einer Spalte aus"
      ],
      "metadata": {
        "id": "RmuDkzhttsQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nicht benötigte Spalten für besseren Überblick entfernen"
      ],
      "metadata": {
        "id": "cl8g6BfXrY3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_list = [\"Paralleltitel\", \"Unterreihe\", \"Beteiligt\"] # Liste an zu löschenden Spalten\n",
        "df = df.drop(columns=delete_list)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "GAw5XGSmrfVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speicherung als Excel"
      ],
      "metadata": {
        "id": "ocDaluO7gwMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(\"Zeitungsliste.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "yxE16juErJqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nächste Schritte"
      ],
      "metadata": {
        "id": "XGRX6Z_TAiCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Für nähere Analyse der zeitlichen Verteilung:** Notebook \"Analyse_Zeitliche_Verteilung.ipynb\"\n",
        "\n",
        "* **Für nähere Analyse der räumlichen Verteilung:** Notebook \"Analyse_Räumliche_Verteilung.ipynb\""
      ],
      "metadata": {
        "id": "PuS9jgDkAMmh"
      }
    }
  ]
}